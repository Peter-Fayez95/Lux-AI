{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Prepare the environment: Lunar Lander","metadata":{}},{"cell_type":"code","source":"!pip install swig\n!pip install gym[box2d]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T01:14:26.289095Z","iopub.execute_input":"2024-12-10T01:14:26.289345Z","iopub.status.idle":"2024-12-10T01:15:24.464109Z","shell.execute_reply.started":"2024-12-10T01:14:26.289309Z","shell.execute_reply":"2024-12-10T01:15:24.463159Z"}},"outputs":[{"name":"stdout","text":"Collecting swig\n  Downloading swig-4.3.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (3.5 kB)\nDownloading swig-4.3.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: swig\nSuccessfully installed swig-4.3.0\nRequirement already satisfied: gym[box2d] in /opt/conda/lib/python3.10/site-packages (0.26.2)\nRequirement already satisfied: numpy>=1.18.0 in /opt/conda/lib/python3.10/site-packages (from gym[box2d]) (1.26.4)\nRequirement already satisfied: cloudpickle>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from gym[box2d]) (3.1.0)\nRequirement already satisfied: gym_notices>=0.0.4 in /opt/conda/lib/python3.10/site-packages (from gym[box2d]) (0.0.8)\nCollecting box2d-py==2.3.5 (from gym[box2d])\n  Downloading box2d-py-2.3.5.tar.gz (374 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting pygame==2.1.0 (from gym[box2d])\n  Downloading pygame-2.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.5 kB)\nRequirement already satisfied: swig==4.* in /opt/conda/lib/python3.10/site-packages (from gym[box2d]) (4.3.0)\nDownloading pygame-2.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: box2d-py\n  Building wheel for box2d-py (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for box2d-py: filename=box2d_py-2.3.5-cp310-cp310-linux_x86_64.whl size=495258 sha256=a8b2376df9e9d370e5c5e8b2992924c3996bee538dbc3f9438c14a5763b09b51\n  Stored in directory: /root/.cache/pip/wheels/db/8f/6a/eaaadf056fba10a98d986f6dce954e6201ba3126926fc5ad9e\nSuccessfully built box2d-py\nInstalling collected packages: box2d-py, pygame\nSuccessfully installed box2d-py-2.3.5 pygame-2.1.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import numpy as np \nimport matplotlib.pyplot as plt\nimport gym\nfrom IPython.display import clear_output\nimport torch\n#from stable_baselines3 import PPO","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-10T01:15:24.468349Z","iopub.execute_input":"2024-12-10T01:15:24.468617Z","iopub.status.idle":"2024-12-10T01:15:27.542180Z","shell.execute_reply.started":"2024-12-10T01:15:24.468588Z","shell.execute_reply":"2024-12-10T01:15:27.541263Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"env = gym.make(\"LunarLander-v2\", render_mode=\"rgb_array\")\nobservation, info = env.reset()\n\nfor _ in range(10):\n    frame = env.render()\n    clear_output(wait=True)\n    # this is where you would insert your policy\n    action = env.action_space.sample()\n    plt.imshow(frame)\n    plt.axis('off')  # Hide the axes\n    plt.show()\n    #plt.pause(0.05)\n    # step (transition) through the environment with the action\n    # receiving the next observation, reward and if the episode has terminated or truncated\n    observation, reward, terminated, truncated, info = env.step(action)\n    # If the episode has ended then we can reset to start a new episode\n    if terminated or truncated:\n        observation, info = env.reset()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T04:00:47.422284Z","iopub.execute_input":"2024-12-10T04:00:47.422621Z","iopub.status.idle":"2024-12-10T04:00:48.853130Z","shell.execute_reply.started":"2024-12-10T04:00:47.422592Z","shell.execute_reply":"2024-12-10T04:00:48.852118Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}],"execution_count":101},{"cell_type":"markdown","source":"# Agent based on RSiMBA architucture: I made a slight modification on the original archticuture SiMBA","metadata":{}},{"cell_type":"code","source":"!pip install einops\n!pip install mamba-ssm==2.2.2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T01:20:14.534234Z","iopub.execute_input":"2024-12-10T01:20:14.534994Z","iopub.status.idle":"2024-12-10T01:20:52.886774Z","shell.execute_reply.started":"2024-12-10T01:20:14.534954Z","shell.execute_reply":"2024-12-10T01:20:52.885824Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: einops in /opt/conda/lib/python3.10/site-packages (0.8.0)\nCollecting mamba-ssm==2.2.2\n  Downloading mamba_ssm-2.2.2.tar.gz (85 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from mamba-ssm==2.2.2) (2.4.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from mamba-ssm==2.2.2) (21.3)\nRequirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from mamba-ssm==2.2.2) (1.11.1.2)\nRequirement already satisfied: einops in /opt/conda/lib/python3.10/site-packages (from mamba-ssm==2.2.2) (0.8.0)\nCollecting triton (from mamba-ssm==2.2.2)\n  Using cached triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from mamba-ssm==2.2.2) (4.46.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->mamba-ssm==2.2.2) (3.1.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->mamba-ssm==2.2.2) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->mamba-ssm==2.2.2) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->mamba-ssm==2.2.2) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->mamba-ssm==2.2.2) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->mamba-ssm==2.2.2) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->mamba-ssm==2.2.2) (2024.6.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers->mamba-ssm==2.2.2) (0.26.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers->mamba-ssm==2.2.2) (1.26.4)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers->mamba-ssm==2.2.2) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->mamba-ssm==2.2.2) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers->mamba-ssm==2.2.2) (2.32.3)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers->mamba-ssm==2.2.2) (0.20.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers->mamba-ssm==2.2.2) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers->mamba-ssm==2.2.2) (4.66.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->mamba-ssm==2.2.2) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->mamba-ssm==2.2.2) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->mamba-ssm==2.2.2) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->mamba-ssm==2.2.2) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->mamba-ssm==2.2.2) (2024.6.2)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->mamba-ssm==2.2.2) (1.3.0)\nUsing cached triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\nBuilding wheels for collected packages: mamba-ssm\n  Building wheel for mamba-ssm (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for mamba-ssm: filename=mamba_ssm-2.2.2-cp310-cp310-linux_x86_64.whl size=323998290 sha256=a658a5438dbe9fb3a53799d7d9f4714ca09225769c24ec04a403728ac7d1c69e\n  Stored in directory: /root/.cache/pip/wheels/57/7c/90/9f963468ecc3791e36e388f9e7b4a4e1e3f90fbb340055aa4d\nSuccessfully built mamba-ssm\nInstalling collected packages: triton, mamba-ssm\nSuccessfully installed mamba-ssm-2.2.2 triton-3.1.0\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"from einops import rearrange, repeat, einsum\nfrom einops.layers.torch import Rearrange\nimport torch.nn.functional as F\nimport torch.nn as nn\ndef count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\nclass MambaBlock(nn.Module):\n    def __init__(self, d_model, d_state = 64, expand = 2, d_conv = 4, conv_bias = True,  bias = False ):\n        \"\"\"A single Mamba block, as described in Figure 3 in Section 3.4 in the Mamba paper [1].\"\"\"\n        super().__init__()\n        self.d_model = d_model # Model dimension d_model\n        self.d_state=d_state # SSM state expansion factor\n        self.d_conv=d_conv  # Local convolution width\n        self.expand=expand  # Block expansion factor\n        self.conv_bias=conv_bias\n        self.bias=bias\n        self.d_inner = int(self.expand * self.d_model)\n        self.dt_rank = math.ceil(self.d_model / 16)\n        \n\n        self.in_proj = nn.Linear(self.d_model, self.d_inner * 2, bias=self.bias)\n\n        self.conv1d = nn.Conv1d(\n            in_channels=self.d_inner,\n            out_channels=self.d_inner,\n            bias=self.conv_bias,\n            kernel_size=self.d_conv,\n            groups=self.d_inner,\n            padding=self.d_conv - 1,\n        )\n\n        # x_proj takes in `x` and outputs the input-specific Δ, B, C\n        self.x_proj = nn.Linear(self.d_inner, self.dt_rank + self.d_state * 2, bias=False)\n        \n        # dt_proj projects Δ from dt_rank to d_in\n        self.dt_proj = nn.Linear(self.dt_rank, self.d_inner, bias=True)\n\n        A = repeat(torch.arange(1, self.d_state + 1), 'n -> d n', d=self.d_inner)\n        self.A_log = nn.Parameter(torch.log(A))\n        self.D = nn.Parameter(torch.ones(self.d_inner))\n        self.out_proj = nn.Linear(self.d_inner, self.d_model, bias=self.bias)\n        \n\n    def forward(self, x):\n        \"\"\"Mamba block forward. This looks the same as Figure 3 in Section 3.4 in the Mamba paper [1].\n    \n        Args:\n            x: shape (b, l, d)    (See Glossary at top for definitions of b, l, d_in, n...)\n    \n        Returns:\n            output: shape (b, l, d)\n        \n        Official Implementation:\n            class Mamba, https://github.com/state-spaces/mamba/blob/main/mamba_ssm/modules/mamba_simple.py#L119\n            mamba_inner_ref(), https://github.com/state-spaces/mamba/blob/main/mamba_ssm/ops/selective_scan_interface.py#L311\n            \n        \"\"\"\n        (b, l, d) = x.shape\n        \n        x_and_res = self.in_proj(x)  # shape (b, l, 2 * d_in)\n        (x, res) = x_and_res.split(split_size=[self.d_inner, self.d_inner], dim=-1)\n\n        x = rearrange(x, 'b l d_in -> b d_in l')\n        x = self.conv1d(x)[:, :, :l]\n        x = rearrange(x, 'b d_in l -> b l d_in')\n        \n        x = F.silu(x)\n\n        y = self.ssm(x)\n        \n        y = y * F.silu(res)\n        \n        output = self.out_proj(y)\n\n        return output\n\n    \n    def ssm(self, x):\n        \"\"\"Runs the SSM. See:\n            - Algorithm 2 in Section 3.2 in the Mamba paper [1]\n            - run_SSM(A, B, C, u) in The Annotated S4 [2]\n\n        Args:\n            x: shape (b, l, d_in)    (See Glossary at top for definitions of b, l, d_in, n...)\n    \n        Returns:\n            output: shape (b, l, d_in)\n\n        Official Implementation:\n            mamba_inner_ref(), https://github.com/state-spaces/mamba/blob/main/mamba_ssm/ops/selective_scan_interface.py#L311\n            \n        \"\"\"\n        (d_in, n) = self.A_log.shape\n\n        # Compute ∆ A B C D, the state space parameters.\n        #     A, D are input independent (see Mamba paper [1] Section 3.5.2 \"Interpretation of A\" for why A isn't selective)\n        #     ∆, B, C are input-dependent (this is a key difference between Mamba and the linear time invariant S4,\n        #                                  and is why Mamba is called **selective** state spaces)\n        \n        A = -torch.exp(self.A_log.float())  # shape (d_in, n)\n        D = self.D.float()\n\n        x_dbl = self.x_proj(x)  # (b, l, dt_rank + 2*n)\n        \n        (delta, B, C) = x_dbl.split(split_size=[self.dt_rank, n, n], dim=-1)  # delta: (b, l, dt_rank). B, C: (b, l, n)\n        delta = F.softplus(self.dt_proj(delta))  # (b, l, d_in)\n        \n        y = self.selective_scan(x, delta, A, B, C, D)  # This is similar to run_SSM(A, B, C, u) in The Annotated S4 [2]\n        \n        return y\n\n    \n    def selective_scan(self, u, delta, A, B, C, D):\n        \"\"\"Does selective scan algorithm. See:\n            - Section 2 State Space Models in the Mamba paper [1]\n            - Algorithm 2 in Section 3.2 in the Mamba paper [1]\n            - run_SSM(A, B, C, u) in The Annotated S4 [2]\n\n        This is the classic discrete state space formula:\n            x(t + 1) = Ax(t) + Bu(t)\n            y(t)     = Cx(t) + Du(t)\n        except B and C (and the step size delta, which is used for discretization) are dependent on the input x(t).\n    \n        Args:\n            u: shape (b, l, d_in)    (See Glossary at top for definitions of b, l, d_in, n...)\n            delta: shape (b, l, d_in)\n            A: shape (d_in, n)\n            B: shape (b, l, n)\n            C: shape (b, l, n)\n            D: shape (d_in,)\n    \n        Returns:\n            output: shape (b, l, d_in)\n    \n        Official Implementation:\n            selective_scan_ref(), https://github.com/state-spaces/mamba/blob/main/mamba_ssm/ops/selective_scan_interface.py#L86\n            Note: I refactored some parts out of `selective_scan_ref` out, so the functionality doesn't match exactly.\n            \n        \"\"\"\n        (b, l, d_in) = u.shape\n        n = A.shape[1]\n        \n        # Discretize continuous parameters (A, B)\n        # - A is discretized using zero-order hold (ZOH) discretization (see Section 2 Equation 4 in the Mamba paper [1])\n        # - B is discretized using a simplified Euler discretization instead of ZOH. From a discussion with authors:\n        #   \"A is the more important term and the performance doesn't change much with the simplification on B\"\n        deltaA = torch.exp(einsum(delta, A, 'b l d_in, d_in n -> b l d_in n'))\n        deltaB_u = einsum(delta, B, u, 'b l d_in, b l n, b l d_in -> b l d_in n')\n        \n        # Perform selective scan (see scan_SSM() in The Annotated S4 [2])\n        # Note that the below is sequential, while the official implementation does a much faster parallel scan that\n        # is additionally hardware-aware (like FlashAttention).\n        x = torch.zeros((b, d_in, n), device=deltaA.device)\n        ys = []    \n        for i in range(l):\n            x = deltaA[:, i] * x + deltaB_u[:, i]\n            y = einsum(x, C[:, i, :], 'b d_in n, b n -> b d_in')\n            ys.append(y)\n        y = torch.stack(ys, dim=1)  # shape (b, l, d_in)\n        \n        y = y + u * D\n    \n        return y","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T01:20:58.749191Z","iopub.execute_input":"2024-12-10T01:20:58.749543Z","iopub.status.idle":"2024-12-10T01:20:58.768121Z","shell.execute_reply.started":"2024-12-10T01:20:58.749510Z","shell.execute_reply":"2024-12-10T01:20:58.767269Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"import math\nfrom mamba_ssm import Mamba\nfrom timm.models.layers import DropPath, to_2tuple, trunc_normal_\n\nclass PVT2FFN(nn.Module):\n    def __init__(self, in_features, hidden_features):\n        super().__init__()\n        self.fc1 = nn.Linear(in_features, hidden_features)\n        self.dwconv = DWConv(hidden_features)\n        self.act = nn.GELU()\n        self.fc2 = nn.Linear(hidden_features, in_features)\n        self.apply(self._init_weights)\n\n    def _init_weights(self, m):\n        if isinstance(m, nn.Linear):\n            trunc_normal_(m.weight, std=.02)\n            if isinstance(m, nn.Linear) and m.bias is not None:\n                nn.init.constant_(m.bias, 0)\n        elif isinstance(m, nn.LayerNorm):\n            nn.init.constant_(m.bias, 0)\n            nn.init.constant_(m.weight, 1.0)\n        elif isinstance(m, nn.Conv2d):\n            fan_out = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n            fan_out //= m.groups\n            m.weight.data.normal_(0, math.sqrt(2.0 / fan_out))\n            if m.bias is not None:\n                m.bias.data.zero_()\n\n    def forward(self, x, H, W):\n        x = self.fc1(x)\n        x = self.dwconv(x, H, W)\n        x = self.act(x)\n        x = self.fc2(x)\n        return x\n\nclass DWConv(nn.Module):\n    def __init__(self, dim=768):\n        super(DWConv, self).__init__()\n        self.dwconv = nn.Conv2d(dim, dim, 3, 1, 1, bias=True, groups=dim)\n\n    def forward(self, x, H, W):\n        #print(x.shape)\n        B, N, C = x.shape\n        x = x.transpose(1, 2).view(B, C, H, W)\n        x = self.dwconv(x)\n        x = x.flatten(2).transpose(1, 2)\n        return x\n\n\n\nclass RSimbaBlock(nn.Module):\n    def __init__(self, embed_dim, height, width):\n        super().__init__()\n        self.mamba = Mamba(d_model=embed_dim, d_state=16, d_conv=8, expand=2) #optimize\n        self.mlp = PVT2FFN(in_features=embed_dim, hidden_features=int(embed_dim * 2))\n        self.norm = nn.LayerNorm(embed_dim)\n        self.height = height\n        self.width = width\n\n    def forward(self, x):\n        #print(x.shape)\n        x_old = x\n        x = self.mamba(x) + x + self.mlp(x,self.height,self.width)\n        return self.norm(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T01:21:19.640751Z","iopub.execute_input":"2024-12-10T01:21:19.641507Z","iopub.status.idle":"2024-12-10T01:21:20.605246Z","shell.execute_reply.started":"2024-12-10T01:21:19.641469Z","shell.execute_reply":"2024-12-10T01:21:20.604297Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/mamba_ssm/ops/selective_scan_interface.py:164: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n  def forward(ctx, xz, conv1d_weight, conv1d_bias, x_proj_weight, delta_proj_weight,\n/opt/conda/lib/python3.10/site-packages/mamba_ssm/ops/selective_scan_interface.py:240: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n  def backward(ctx, dout):\n/opt/conda/lib/python3.10/site-packages/mamba_ssm/ops/triton/layer_norm.py:986: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n  def forward(\n/opt/conda/lib/python3.10/site-packages/mamba_ssm/ops/triton/layer_norm.py:1045: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n  def backward(ctx, dout, *args):\n/opt/conda/lib/python3.10/site-packages/mamba_ssm/distributed/tensor_parallel.py:26: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n  def forward(ctx, x, weight, bias, process_group=None, sequence_parallel=True):\n/opt/conda/lib/python3.10/site-packages/mamba_ssm/distributed/tensor_parallel.py:62: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n  def backward(ctx, grad_output):\n/opt/conda/lib/python3.10/site-packages/mamba_ssm/ops/triton/ssd_combined.py:758: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n  def forward(ctx, zxbcdt, conv1d_weight, conv1d_bias, dt_bias, A, D, chunk_size, initial_states=None, seq_idx=None, dt_limit=(0.0, float(\"inf\")), return_final_states=False, activation=\"silu\",\n/opt/conda/lib/python3.10/site-packages/mamba_ssm/ops/triton/ssd_combined.py:836: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n  def backward(ctx, dout, *args):\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"class ConvToMamba(nn.Module):\n    def __init__(self):\n        super(ConvToMamba, self).__init__()\n        self.rearrange = Rearrange('b (n c) -> b n c', c = 64, n = 64)\n\n        \n    def forward(self, x):\n        # Define the computation for the forward pass\n        # For example, a simple linear transformation: x * weight + bias\n        return self.rearrange(x)\n\nclass MambaToConv(nn.Module):\n    def __init__(self):\n        super(MambaToConv, self).__init__()\n        self.rearrange = Rearrange('b n c -> b (n c)')\n\n        \n    def forward(self, x):\n        # Define the computation for the forward pass\n        # For example, a simple linear transformation: x * weight + bias\n        return self.rearrange(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T02:32:48.915776Z","iopub.execute_input":"2024-12-10T02:32:48.916111Z","iopub.status.idle":"2024-12-10T02:32:48.922082Z","shell.execute_reply.started":"2024-12-10T02:32:48.916083Z","shell.execute_reply":"2024-12-10T02:32:48.921047Z"}},"outputs":[],"execution_count":67},{"cell_type":"code","source":"from torch.distributions.categorical import Categorical\n\n\nclass Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n        self.basemodel = nn.Sequential(\n            nn.Linear(8,64),\n            nn.ReLU(),\n            nn.Linear(64,512),\n            nn.ReLU(),\n            nn.Linear(512,4096),\n            ConvToMamba(),\n            *[RSimbaBlock(\n                embed_dim = 64,\n                height = 8,\n                width = 8,\n            ) for _ in range(4)],\n            MambaToConv(),\n        )\n        self.actor = nn.Sequential(\n            nn.Linear(4096,256),\n            nn.ReLU(),\n            nn.Linear(256,32),\n            nn.ReLU(),\n            nn.Linear(32,4)\n        )\n        self.critic = nn.Sequential(\n            nn.Linear(4096,512),\n            nn.ReLU(),\n            nn.Linear(512,64),\n            nn.ReLU(),\n            nn.Linear(64,8),\n            nn.ReLU(),\n            nn.Linear(8,1),\n        )\n\n    def get_value(self, x):\n        return self.critic(self.basemodel(x))\n\n    \n    def forward(self, x, action=None):\n        x = self.basemodel(x)\n        logits = self.actor(x)\n        probs = Categorical(logits=logits)\n        if action is None:\n            action = probs.sample()\n        return action, probs.log_prob(action), probs.entropy(), self.critic(x)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T02:36:03.559525Z","iopub.execute_input":"2024-12-10T02:36:03.559869Z","iopub.status.idle":"2024-12-10T02:36:03.568086Z","shell.execute_reply.started":"2024-12-10T02:36:03.559838Z","shell.execute_reply":"2024-12-10T02:36:03.567143Z"}},"outputs":[],"execution_count":73},{"cell_type":"code","source":"def make_env(env_id, seed, idx, capture_video):\n    def thunk():\n        env = gym.make(env_id)\n        env = gym.wrappers.RecordEpisodeStatistics(env)\n        if capture_video:\n            if idx == 0:\n                env = gym.wrappers.RecordVideo(env, f\"videos/ch\")\n        return env\n\n    return thunk\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nenvs = gym.vector.SyncVectorEnv(\n        [make_env(\"LunarLander-v2\", 1 + i, i, False) for i in range(4)]\n    )\n\nagent = nn.DataParallel(Model()).to(device)\n#agent = Model().to(device)\noptimizer = torch.optim.Adam(agent.parameters(), lr=2.5e-4, eps=1e-5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T02:36:13.446325Z","iopub.execute_input":"2024-12-10T02:36:13.447287Z","iopub.status.idle":"2024-12-10T02:36:13.510370Z","shell.execute_reply.started":"2024-12-10T02:36:13.447248Z","shell.execute_reply":"2024-12-10T02:36:13.509656Z"}},"outputs":[],"execution_count":74},{"cell_type":"markdown","source":"# Training with PPO and GAE: the training done on 4 runs for this cell with different gamma and gae_lambda values","metadata":{}},{"cell_type":"code","source":"# ALGO Logic: Storage setup\nanneal_lr = True\ngae = True\nnorm_adv = True\nclip_vloss = True\nnum_steps = 128\nnum_envs = 4\nlearning_rate = 2.5e-4\noptimizer.param_groups[0][\"lr\"] = learning_rate\ntotal_timesteps = 50000\nbatch_size = num_envs * num_steps\ngamma = 0.999\ngae_lambda = 0.95\nnum_minibatches = 4\nupdate_epochs = 4\nclip_coef = 0.2\nent_coef = 0.01\nvf_coef = 0.5\nmax_grad_norm = 0.5\nminibatch_size = batch_size // num_minibatches\ntarget_kl = None\n\n\n\nobs = torch.zeros((num_steps, num_envs) + envs.single_observation_space.shape).to(device)\nactions = torch.zeros((num_steps, num_envs) + envs.single_action_space.shape).to(device)\nlogprobs = torch.zeros((num_steps, num_envs)).to(device)\nrewards = torch.zeros((num_steps, num_envs)).to(device)\ndones = torch.zeros((num_steps, num_envs)).to(device)\nvalues = torch.zeros((num_steps, num_envs)).to(device)\n# Start the game\nglobal_step = 0\nnext_obs = torch.Tensor(envs.reset()[0]).to(device)\nnext_done = torch.zeros(4).to(device)\nnum_updates = total_timesteps // batch_size\n\nfor update in range(1, num_updates + 1):\n    # Annealing the rate if instructed to do so.\n    if anneal_lr:\n        frac = 1.0 - (update - 1.0) / num_updates\n        lrnow = frac * learning_rate\n        optimizer.param_groups[0][\"lr\"] = lrnow\n\n    for step in range(num_steps):\n        global_step += 1 * num_envs\n        obs[step] = next_obs\n        dones[step] = next_done\n\n        # ALGO LOGIC: action logic\n        with torch.no_grad():\n            action, logprob, _, value = agent(next_obs)\n            values[step] = value.flatten()\n        actions[step] = action\n        logprobs[step] = logprob\n\n        # TRY NOT TO MODIFY: execute the game and log data.\n        next_obs, reward, terminated, truncated, info = envs.step(action.cpu().numpy())\n        done  = terminated + truncated\n        rewards[step] = torch.tensor(reward).to(device).view(-1)\n        next_obs, next_done = torch.Tensor(next_obs).to(device), torch.Tensor(done).to(device)\n        \n        #print(info)\n        if info and \"final_info\" in info.keys():\n            for elem in info['final_info']:\n                if elem:\n                    print(f\"global_step={global_step}, episodic_return= {elem['episode']['r']}, episodic_length= {elem['episode']['l']}\")\n\n    # bootstrap value if not done\n    with torch.no_grad():\n        next_value = agent(next_obs)[3].reshape(1, -1)\n        if gae:\n            advantages = torch.zeros_like(rewards).to(device)\n            lastgaelam = 0\n            for t in reversed(range(num_steps)):\n                if t == num_steps - 1:\n                    nextnonterminal = 1.0 - next_done\n                    nextvalues = next_value\n                else:\n                    nextnonterminal = 1.0 - dones[t + 1]\n                    nextvalues = values[t + 1]\n                delta = rewards[t] + gamma * nextvalues * nextnonterminal - values[t]\n                advantages[t] = lastgaelam = delta + gamma * gae_lambda * nextnonterminal * lastgaelam\n            returns = advantages + values\n        else:\n            returns = torch.zeros_like(rewards).to(device)\n            for t in reversed(range(num_steps)):\n                if t == num_steps - 1:\n                    nextnonterminal = 1.0 - next_done\n                    next_return = next_value\n                else:\n                    nextnonterminal = 1.0 - dones[t + 1]\n                    next_return = returns[t + 1]\n                returns[t] = rewards[t] + gamma * nextnonterminal * next_return\n            advantages = returns - values\n\n    # flatten the batch\n    b_obs = obs.reshape((-1,) + envs.single_observation_space.shape)\n    b_logprobs = logprobs.reshape(-1)\n    b_actions = actions.reshape((-1,) + envs.single_action_space.shape)\n    b_advantages = advantages.reshape(-1)\n    b_returns = returns.reshape(-1)\n    b_values = values.reshape(-1)\n\n    # Optimizing the policy and value network\n    b_inds = np.arange(batch_size)\n    clipfracs = []\n    for epoch in range(update_epochs):\n        np.random.shuffle(b_inds)\n        for start in range(0, batch_size, minibatch_size):\n            end = start + minibatch_size\n            mb_inds = b_inds[start:end]\n\n            _, newlogprob, entropy, newvalue = agent(\n                b_obs[mb_inds], b_actions.long()[mb_inds]\n            )\n            logratio = newlogprob - b_logprobs[mb_inds]\n            ratio = logratio.exp()\n\n            with torch.no_grad():\n                # calculate approx_kl http://joschu.net/blog/kl-approx.html\n                old_approx_kl = (-logratio).mean()\n                approx_kl = ((ratio - 1) - logratio).mean()\n                clipfracs += [((ratio - 1.0).abs() > clip_coef).float().mean().item()]\n\n            mb_advantages = b_advantages[mb_inds]\n            if norm_adv:\n                mb_advantages = (mb_advantages - mb_advantages.mean()) / (mb_advantages.std() + 1e-8)\n\n            # Policy loss\n            pg_loss1 = -mb_advantages * ratio\n            pg_loss2 = -mb_advantages * torch.clamp(ratio, 1 - clip_coef, 1 + clip_coef)\n            pg_loss = torch.max(pg_loss1, pg_loss2).mean()\n\n            # Value loss\n            newvalue = newvalue.view(-1)\n            if clip_vloss:\n                v_loss_unclipped = (newvalue - b_returns[mb_inds]) ** 2\n                v_clipped = b_values[mb_inds] + torch.clamp(\n                    newvalue - b_values[mb_inds],\n                    -clip_coef,\n                    clip_coef,\n                )\n                v_loss_clipped = (v_clipped - b_returns[mb_inds]) ** 2\n                v_loss_max = torch.max(v_loss_unclipped, v_loss_clipped)\n                v_loss = 0.5 * v_loss_max.mean()\n            else:\n                v_loss = 0.5 * ((newvalue - b_returns[mb_inds]) ** 2).mean()\n\n            entropy_loss = entropy.mean()\n            loss = pg_loss - ent_coef * entropy_loss + v_loss * vf_coef\n\n            optimizer.zero_grad()\n            loss.backward()\n            nn.utils.clip_grad_norm_(agent.parameters(), max_grad_norm)\n            optimizer.step()\n\n        if target_kl is not None:\n            if approx_kl > target_kl:\n                break\n\n    y_pred, y_true = b_values.cpu().numpy(), b_returns.cpu().numpy()\n    var_y = np.var(y_true)\n    explained_var = np.nan if var_y == 0 else 1 - np.var(y_true - y_pred) / var_y","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T03:13:45.382847Z","iopub.execute_input":"2024-12-10T03:13:45.383227Z","iopub.status.idle":"2024-12-10T03:18:41.903391Z","shell.execute_reply.started":"2024-12-10T03:13:45.383196Z","shell.execute_reply":"2024-12-10T03:18:41.902273Z"}},"outputs":[{"name":"stdout","text":"global_step=1208, episodic_return= 240.30487060546875, episodic_length= 302\nglobal_step=1732, episodic_return= 231.2761993408203, episodic_length= 433\nglobal_step=2200, episodic_return= 209.15615844726562, episodic_length= 550\nglobal_step=2304, episodic_return= -1.9642257690429688, episodic_length= 143\nglobal_step=2328, episodic_return= 276.2862548828125, episodic_length= 280\nglobal_step=2556, episodic_return= 168.24313354492188, episodic_length= 639\nglobal_step=3764, episodic_return= 269.35491943359375, episodic_length= 302\nglobal_step=3988, episodic_return= 195.4248809814453, episodic_length= 421\nglobal_step=4124, episodic_return= 194.37103271484375, episodic_length= 449\nglobal_step=4568, episodic_return= 283.5459289550781, episodic_length= 592\nglobal_step=4932, episodic_return= 251.20330810546875, episodic_length= 236\nglobal_step=5028, episodic_return= 296.57568359375, episodic_length= 226\nglobal_step=5176, episodic_return= 214.96484375, episodic_length= 353\nglobal_step=5632, episodic_return= 297.8149719238281, episodic_length= 175\nglobal_step=5820, episodic_return= 300.6912841796875, episodic_length= 198\nglobal_step=6056, episodic_return= 200.6689910888672, episodic_length= 372\nglobal_step=6776, episodic_return= 288.29498291015625, episodic_length= 286\nglobal_step=7088, episodic_return= 155.11285400390625, episodic_length= 478\nglobal_step=7320, episodic_return= -141.0492401123047, episodic_length= 136\nglobal_step=7676, episodic_return= 217.0516815185547, episodic_length= 464\nglobal_step=7876, episodic_return= 251.26271057128906, episodic_length= 455\nglobal_step=8868, episodic_return= 223.364013671875, episodic_length= 445\nglobal_step=9232, episodic_return= 210.66485595703125, episodic_length= 389\nglobal_step=9268, episodic_return= 263.0943603515625, episodic_length= 348\nglobal_step=9312, episodic_return= 170.7827606201172, episodic_length= 498\nglobal_step=9384, episodic_return= -38.39373016357422, episodic_length= 129\nglobal_step=9852, episodic_return= -130.65765380859375, episodic_length= 117\nglobal_step=10492, episodic_return= 247.34059143066406, episodic_length= 306\nglobal_step=10504, episodic_return= 240.62594604492188, episodic_length= 318\nglobal_step=10688, episodic_return= 221.42147827148438, episodic_length= 344\nglobal_step=10820, episodic_return= 242.11672973632812, episodic_length= 242\nglobal_step=11060, episodic_return= 18.377777099609375, episodic_length= 142\nglobal_step=11480, episodic_return= 287.0699157714844, episodic_length= 244\nglobal_step=11820, episodic_return= 264.3960266113281, episodic_length= 283\nglobal_step=12040, episodic_return= 45.191192626953125, episodic_length= 305\nglobal_step=12212, episodic_return= 258.74658203125, episodic_length= 288\nglobal_step=12816, episodic_return= 244.88064575195312, episodic_length= 334\nglobal_step=13040, episodic_return= 225.33200073242188, episodic_length= 305\nglobal_step=13060, episodic_return= 257.74554443359375, episodic_length= 255\nglobal_step=13748, episodic_return= 157.51290893554688, episodic_length= 384\nglobal_step=13880, episodic_return= 10.274642944335938, episodic_length= 205\nglobal_step=13888, episodic_return= 247.2427215576172, episodic_length= 268\nglobal_step=14128, episodic_return= 245.4619140625, episodic_length= 272\nglobal_step=14272, episodic_return= 22.7515869140625, episodic_length= 96\nglobal_step=14784, episodic_return= 241.20191955566406, episodic_length= 226\nglobal_step=14912, episodic_return= 248.275390625, episodic_length= 291\nglobal_step=15288, episodic_return= 249.41688537597656, episodic_length= 254\nglobal_step=15512, episodic_return= 243.3777618408203, episodic_length= 346\nglobal_step=15764, episodic_return= 258.92864990234375, episodic_length= 245\nglobal_step=16128, episodic_return= 24.14026641845703, episodic_length= 154\nglobal_step=16592, episodic_return= 236.90280151367188, episodic_length= 326\nglobal_step=16628, episodic_return= 185.35128784179688, episodic_length= 429\nglobal_step=16812, episodic_return= 277.56817626953125, episodic_length= 262\nglobal_step=17144, episodic_return= 11.822601318359375, episodic_length= 129\nglobal_step=17420, episodic_return= 280.31414794921875, episodic_length= 323\nglobal_step=17604, episodic_return= 43.76556396484375, episodic_length= 115\nglobal_step=17628, episodic_return= 257.3659973144531, episodic_length= 259\nglobal_step=18128, episodic_return= 284.1268005371094, episodic_length= 329\nglobal_step=18472, episodic_return= 252.1484375, episodic_length= 263\nglobal_step=18720, episodic_return= 247.55580139160156, episodic_length= 273\nglobal_step=18932, episodic_return= 14.96148681640625, episodic_length= 115\nglobal_step=19204, episodic_return= 11.7012939453125, episodic_length= 121\nglobal_step=19332, episodic_return= 234.3760986328125, episodic_length= 301\nglobal_step=19672, episodic_return= -108.89096069335938, episodic_length= 517\nglobal_step=20072, episodic_return= 236.5001983642578, episodic_length= 285\nglobal_step=20156, episodic_return= 243.03976440429688, episodic_length= 238\nglobal_step=20740, episodic_return= 223.4677734375, episodic_length= 267\nglobal_step=20892, episodic_return= 292.4219055175781, episodic_length= 184\nglobal_step=21084, episodic_return= 130.4637451171875, episodic_length= 438\nglobal_step=21256, episodic_return= 238.87440490722656, episodic_length= 296\nglobal_step=21484, episodic_return= 50.291473388671875, episodic_length= 186\nglobal_step=21932, episodic_return= 288.56866455078125, episodic_length= 212\nglobal_step=21976, episodic_return= 61.308685302734375, episodic_length= 123\nglobal_step=22148, episodic_return= 274.285400390625, episodic_length= 314\nglobal_step=22336, episodic_return= 236.96600341796875, episodic_length= 270\nglobal_step=22416, episodic_return= 47.76763916015625, episodic_length= 121\nglobal_step=22616, episodic_return= -12.129951477050781, episodic_length= 117\nglobal_step=22772, episodic_return= 30.231796264648438, episodic_length= 199\nglobal_step=23104, episodic_return= 41.076202392578125, episodic_length= 122\nglobal_step=23140, episodic_return= 16.408485412597656, episodic_length= 92\nglobal_step=23308, episodic_return= 270.80999755859375, episodic_length= 243\nglobal_step=23380, episodic_return= 260.3636169433594, episodic_length= 241\nglobal_step=24084, episodic_return= 261.1029052734375, episodic_length= 245\nglobal_step=24148, episodic_return= 255.89907836914062, episodic_length= 252\nglobal_step=24384, episodic_return= 263.5177001953125, episodic_length= 269\nglobal_step=24440, episodic_return= 40.3685302734375, episodic_length= 89\nglobal_step=24468, episodic_return= 251.61090087890625, episodic_length= 272\nglobal_step=24852, episodic_return= 274.403564453125, episodic_length= 176\nglobal_step=24852, episodic_return= 58.39576721191406, episodic_length= 117\nglobal_step=24908, episodic_return= 33.092041015625, episodic_length= 117\nglobal_step=25304, episodic_return= 26.93267822265625, episodic_length= 209\nglobal_step=25544, episodic_return= 8.548301696777344, episodic_length= 173\nglobal_step=25840, episodic_return= 243.8559112548828, episodic_length= 233\nglobal_step=26100, episodic_return= 3.380279541015625, episodic_length= 139\nglobal_step=26268, episodic_return= 271.69317626953125, episodic_length= 241\nglobal_step=26304, episodic_return= 232.0572967529297, episodic_length= 363\nglobal_step=26456, episodic_return= 19.41120147705078, episodic_length= 154\nglobal_step=26496, episodic_return= 15.946075439453125, episodic_length= 99\nglobal_step=26904, episodic_return= 0.0717315673828125, episodic_length= 112\nglobal_step=26916, episodic_return= 40.502410888671875, episodic_length= 105\nglobal_step=27252, episodic_return= 244.6311798095703, episodic_length= 246\nglobal_step=27304, episodic_return= 21.11553955078125, episodic_length= 100\nglobal_step=27436, episodic_return= 36.807769775390625, episodic_length= 130\nglobal_step=27584, episodic_return= -212.72665405273438, episodic_length= 320\nglobal_step=27992, episodic_return= 285.7931823730469, episodic_length= 185\nglobal_step=28296, episodic_return= 255.7894744873047, episodic_length= 215\nglobal_step=28316, episodic_return= 276.75421142578125, episodic_length= 253\nglobal_step=28376, episodic_return= 303.956298828125, episodic_length= 198\nglobal_step=28456, episodic_return= -12.260063171386719, episodic_length= 116\nglobal_step=28660, episodic_return= 49.89079284667969, episodic_length= 86\nglobal_step=29204, episodic_return= 254.66505432128906, episodic_length= 227\nglobal_step=29296, episodic_return= 252.03817749023438, episodic_length= 230\nglobal_step=29460, episodic_return= 219.8846435546875, episodic_length= 251\nglobal_step=29480, episodic_return= 241.341552734375, episodic_length= 205\nglobal_step=29956, episodic_return= -6.1540985107421875, episodic_length= 165\nglobal_step=30028, episodic_return= 249.93467712402344, episodic_length= 206\nglobal_step=30028, episodic_return= 14.143501281738281, episodic_length= 137\nglobal_step=30364, episodic_return= 274.6160888671875, episodic_length= 226\nglobal_step=30744, episodic_return= 277.45098876953125, episodic_length= 197\nglobal_step=30900, episodic_return= 258.59613037109375, episodic_length= 218\nglobal_step=30996, episodic_return= 278.8939208984375, episodic_length= 242\nglobal_step=31052, episodic_return= -2.64324951171875, episodic_length= 172\nglobal_step=31576, episodic_return= -134.00732421875, episodic_length= 131\nglobal_step=31600, episodic_return= 30.8492431640625, episodic_length= 175\nglobal_step=31828, episodic_return= 282.445556640625, episodic_length= 208\nglobal_step=31976, episodic_return= 14.670463562011719, episodic_length= 94\nglobal_step=32100, episodic_return= 193.96743774414062, episodic_length= 339\nglobal_step=32344, episodic_return= 257.6192932128906, episodic_length= 192\nglobal_step=32544, episodic_return= -7.761810302734375, episodic_length= 111\nglobal_step=32872, episodic_return= 248.06027221679688, episodic_length= 261\nglobal_step=32984, episodic_return= 254.63238525390625, episodic_length= 252\nglobal_step=33124, episodic_return= 50.270416259765625, episodic_length= 145\nglobal_step=33416, episodic_return= 257.46563720703125, episodic_length= 268\nglobal_step=33600, episodic_return= 55.374176025390625, episodic_length= 154\nglobal_step=33976, episodic_return= 50.673828125, episodic_length= 140\nglobal_step=34160, episodic_return= 274.7437438964844, episodic_length= 322\nglobal_step=34300, episodic_return= 230.01487731933594, episodic_length= 294\nglobal_step=34408, episodic_return= 244.6360321044922, episodic_length= 202\nglobal_step=34516, episodic_return= 31.001419067382812, episodic_length= 89\nglobal_step=34540, episodic_return= 5.1985931396484375, episodic_length= 141\nglobal_step=34764, episodic_return= 19.415435791015625, episodic_length= 116\nglobal_step=34956, episodic_return= 27.871490478515625, episodic_length= 137\nglobal_step=35196, episodic_return= 20.292831420898438, episodic_length= 164\nglobal_step=35344, episodic_return= 51.82350158691406, episodic_length= 145\nglobal_step=35480, episodic_return= 264.37567138671875, episodic_length= 241\nglobal_step=35580, episodic_return= 60.279632568359375, episodic_length= 96\nglobal_step=35960, episodic_return= 276.9853820800781, episodic_length= 251\nglobal_step=36072, episodic_return= 279.9793701171875, episodic_length= 182\nglobal_step=36492, episodic_return= 26.878921508789062, episodic_length= 133\nglobal_step=36548, episodic_return= 44.070068359375, episodic_length= 119\nglobal_step=36956, episodic_return= 24.482009887695312, episodic_length= 102\nglobal_step=37012, episodic_return= -44.14479064941406, episodic_length= 383\nglobal_step=37304, episodic_return= 289.23699951171875, episodic_length= 203\nglobal_step=37572, episodic_return= 171.51124572753906, episodic_length= 498\nglobal_step=37756, episodic_return= 258.7543640136719, episodic_length= 200\nglobal_step=37996, episodic_return= 238.10134887695312, episodic_length= 246\nglobal_step=38148, episodic_return= -2.4530868530273438, episodic_length= 98\nglobal_step=38184, episodic_return= 265.3975830078125, episodic_length= 220\nglobal_step=38592, episodic_return= 259.0257568359375, episodic_length= 255\nglobal_step=38884, episodic_return= 30.984054565429688, episodic_length= 175\nglobal_step=38924, episodic_return= 269.08929443359375, episodic_length= 232\nglobal_step=39032, episodic_return= 265.6695861816406, episodic_length= 221\nglobal_step=39284, episodic_return= 40.968658447265625, episodic_length= 173\nglobal_step=39572, episodic_return= 31.663619995117188, episodic_length= 162\nglobal_step=39656, episodic_return= -8.482231140136719, episodic_length= 93\nglobal_step=39708, episodic_return= 23.452125549316406, episodic_length= 169\nglobal_step=39848, episodic_return= 263.37261962890625, episodic_length= 241\nglobal_step=40124, episodic_return= -26.885887145996094, episodic_length= 138\nglobal_step=40284, episodic_return= 50.00260925292969, episodic_length= 157\nglobal_step=40584, episodic_return= 18.91100311279297, episodic_length= 184\nglobal_step=40660, episodic_return= 262.57904052734375, episodic_length= 238\nglobal_step=40928, episodic_return= 238.6957550048828, episodic_length= 201\nglobal_step=41140, episodic_return= 11.739601135253906, episodic_length= 139\nglobal_step=41212, episodic_return= 234.74197387695312, episodic_length= 232\nglobal_step=41464, episodic_return= -4.2303619384765625, episodic_length= 134\nglobal_step=41604, episodic_return= 26.07245635986328, episodic_length= 116\nglobal_step=41840, episodic_return= 265.3476257324219, episodic_length= 295\nglobal_step=42172, episodic_return= 274.71551513671875, episodic_length= 240\nglobal_step=42368, episodic_return= 251.1947784423828, episodic_length= 226\nglobal_step=42464, episodic_return= 248.47088623046875, episodic_length= 215\nglobal_step=43112, episodic_return= 281.4593505859375, episodic_length= 318\nglobal_step=43436, episodic_return= 253.08692932128906, episodic_length= 267\nglobal_step=43536, episodic_return= 266.3778076171875, episodic_length= 268\nglobal_step=43900, episodic_return= 164.08619689941406, episodic_length= 432\nglobal_step=44108, episodic_return= 25.38616943359375, episodic_length= 168\nglobal_step=44132, episodic_return= 231.90394592285156, episodic_length= 255\nglobal_step=44372, episodic_return= 43.74729919433594, episodic_length= 118\nglobal_step=44564, episodic_return= 264.486083984375, episodic_length= 257\nglobal_step=44584, episodic_return= 49.869171142578125, episodic_length= 119\nglobal_step=44708, episodic_return= 16.185508728027344, episodic_length= 144\nglobal_step=44988, episodic_return= 53.75384521484375, episodic_length= 101\nglobal_step=45328, episodic_return= 20.75281524658203, episodic_length= 191\nglobal_step=45340, episodic_return= 264.741455078125, episodic_length= 242\nglobal_step=45848, episodic_return= 265.0120544433594, episodic_length= 285\nglobal_step=46100, episodic_return= 249.2875213623047, episodic_length= 278\nglobal_step=46456, episodic_return= 260.2095947265625, episodic_length= 279\nglobal_step=46488, episodic_return= 266.553466796875, episodic_length= 290\nglobal_step=47048, episodic_return= 269.5190734863281, episodic_length= 300\nglobal_step=47584, episodic_return= 260.7949523925781, episodic_length= 282\nglobal_step=47988, episodic_return= 247.8563690185547, episodic_length= 472\nglobal_step=48204, episodic_return= 243.003173828125, episodic_length= 289\nglobal_step=48888, episodic_return= 257.84210205078125, episodic_length= 326\nglobal_step=49080, episodic_return= 11.580787658691406, episodic_length= 219\nglobal_step=49096, episodic_return= 169.12002563476562, episodic_length= 652\nglobal_step=49188, episodic_return= 237.0108184814453, episodic_length= 300\n","output_type":"stream"}],"execution_count":84},{"cell_type":"markdown","source":"# Show the agent performance","metadata":{}},{"cell_type":"code","source":"observation, info = env.reset()\n\nnum_epsiodes = 30\naverage_return = 0\nnum_epsiode = 0\nepisodic_return = 0\n\nwhile num_epsiode < num_epsiodes:\n    action, ll, ll, lll = agent(torch.tensor(observation).reshape((1,8)).to(device) )\n    observation, reward, terminated, truncated, info = env.step(action.cpu().item())\n    episodic_return += reward\n    \n    if terminated or truncated:\n        num_epsiode += 1 \n        average_return += episodic_return\n        print(f\"Return of epsiode {num_epsiode}: {episodic_return}\")\n        episodic_return = 0\n        observation, info = env.reset()\n\nprint(f\"average return: {average_return/num_epsiodes}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T04:04:44.149752Z","iopub.execute_input":"2024-12-10T04:04:44.150207Z","iopub.status.idle":"2024-12-10T04:06:24.391126Z","shell.execute_reply.started":"2024-12-10T04:04:44.150171Z","shell.execute_reply":"2024-12-10T04:06:24.390250Z"}},"outputs":[{"name":"stdout","text":"Return of epsiode 1: 261.19630332392444\nReturn of epsiode 2: 47.558230435464594\nReturn of epsiode 3: 233.65632267195508\nReturn of epsiode 4: 237.1796998749008\nReturn of epsiode 5: 208.10385876150957\nReturn of epsiode 6: 197.7399605221769\nReturn of epsiode 7: 53.28205655865645\nReturn of epsiode 8: 233.26461209114282\nReturn of epsiode 9: 246.14755220063216\nReturn of epsiode 10: 236.54803145172238\nReturn of epsiode 11: 245.20213659666052\nReturn of epsiode 12: 260.23762056983924\nReturn of epsiode 13: 275.9669130848884\nReturn of epsiode 14: 20.79055758749172\nReturn of epsiode 15: 241.2352832470545\nReturn of epsiode 16: 261.85924293819477\nReturn of epsiode 17: 225.48537238069125\nReturn of epsiode 18: 266.75234107507254\nReturn of epsiode 19: 224.0910665709447\nReturn of epsiode 20: 257.56875740949584\nReturn of epsiode 21: 252.30888159324084\nReturn of epsiode 22: 227.36905190253628\nReturn of epsiode 23: 244.19390005290666\nReturn of epsiode 24: 277.65619729821447\nReturn of epsiode 25: 285.2690471013185\nReturn of epsiode 26: 268.10793322462473\nReturn of epsiode 27: 161.4104447367531\nReturn of epsiode 28: 195.30312936150187\nReturn of epsiode 29: 297.6104535902922\nReturn of epsiode 30: 239.40041595285652\naverage return: 222.74984580555548\n","output_type":"stream"}],"execution_count":105},{"cell_type":"code","source":"observation, info = env.reset()\n\nfor _ in range(400):\n    frame = env.render()\n    clear_output(wait=True)\n    action, ll, ll, lll = agent(torch.tensor(observation).reshape((1,8)).to(device) )\n    plt.imshow(frame)\n    plt.axis('off')  # Hide the axes\n    plt.show()\n    #plt.pause(0.05)\n    observation, reward, terminated, truncated, info = env.step(action.cpu().item())\n    if terminated or truncated:\n        observation, info = env.reset()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T03:20:42.916570Z","iopub.execute_input":"2024-12-10T03:20:42.916846Z","iopub.status.idle":"2024-12-10T03:21:27.341014Z","shell.execute_reply.started":"2024-12-10T03:20:42.916819Z","shell.execute_reply":"2024-12-10T03:21:27.339924Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}],"execution_count":86},{"cell_type":"code","source":"!pip install moviepy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T03:24:09.252117Z","iopub.execute_input":"2024-12-10T03:24:09.253013Z","iopub.status.idle":"2024-12-10T03:24:18.855752Z","shell.execute_reply.started":"2024-12-10T03:24:09.252969Z","shell.execute_reply":"2024-12-10T03:24:18.854831Z"}},"outputs":[{"name":"stdout","text":"Collecting moviepy\n  Downloading moviepy-2.1.1-py3-none-any.whl.metadata (6.9 kB)\nRequirement already satisfied: decorator<6.0,>=4.0.2 in /opt/conda/lib/python3.10/site-packages (from moviepy) (5.1.1)\nRequirement already satisfied: imageio<3.0,>=2.5 in /opt/conda/lib/python3.10/site-packages (from moviepy) (2.34.1)\nCollecting imageio_ffmpeg>=0.2.0 (from moviepy)\n  Downloading imageio_ffmpeg-0.5.1-py3-none-manylinux2010_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: numpy>=1.25.0 in /opt/conda/lib/python3.10/site-packages (from moviepy) (1.26.4)\nCollecting proglog<=1.0.0 (from moviepy)\n  Downloading proglog-0.1.10-py3-none-any.whl.metadata (639 bytes)\nRequirement already satisfied: python-dotenv>=0.10 in /opt/conda/lib/python3.10/site-packages (from moviepy) (1.0.1)\nRequirement already satisfied: pillow<11.0,>=9.2.0 in /opt/conda/lib/python3.10/site-packages (from moviepy) (10.3.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from imageio_ffmpeg>=0.2.0->moviepy) (70.0.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from proglog<=1.0.0->moviepy) (4.66.4)\nDownloading moviepy-2.1.1-py3-none-any.whl (123 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.5/123.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading imageio_ffmpeg-0.5.1-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading proglog-0.1.10-py3-none-any.whl (6.1 kB)\nInstalling collected packages: proglog, imageio_ffmpeg, moviepy\nSuccessfully installed imageio_ffmpeg-0.5.1 moviepy-2.1.1 proglog-0.1.10\n","output_type":"stream"}],"execution_count":89},{"cell_type":"code","source":"observation, info = env.reset()\n\nvideo_folder = '/kaggle/working/recorded_videos'\nenv_rec = gym.wrappers.RecordVideo(env, video_folder)\n\nfor _ in range(500):\n    frame = env.render()\n    clear_output(wait=True)\n    action, ll, ll, lll = agent(torch.tensor(observation).reshape((1,8)).to(device) )\n    plt.imshow(frame)\n    plt.axis('off')  # Hide the axes\n    plt.show()\n    #plt.pause(0.05)\n    observation, reward, terminated, truncated, info = env_rec.step(action.cpu().item())\n    if terminated or truncated:\n        observation, info = env.reset()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T03:42:44.152942Z","iopub.execute_input":"2024-12-10T03:42:44.153313Z","iopub.status.idle":"2024-12-10T03:43:48.170030Z","shell.execute_reply.started":"2024-12-10T03:42:44.153280Z","shell.execute_reply":"2024-12-10T03:43:48.169100Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}],"execution_count":94},{"cell_type":"markdown","source":"# Save agent","metadata":{}},{"cell_type":"code","source":"# Save the agent state_dict\ntorch.save(agent.state_dict(), 'agent_lunar_lander.pth')\ntorch.save(agent, 'agent_full.pth')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T03:46:21.026834Z","iopub.execute_input":"2024-12-10T03:46:21.027679Z","iopub.status.idle":"2024-12-10T03:46:21.115649Z","shell.execute_reply.started":"2024-12-10T03:46:21.027642Z","shell.execute_reply":"2024-12-10T03:46:21.114707Z"}},"outputs":[],"execution_count":95}]}